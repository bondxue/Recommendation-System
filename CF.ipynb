{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "trainingset_file = 'dataset/ml-100k/u3.base'\n",
    "testset_file= 'dataset/ml-100k/u3.test'\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "ratings = np.zeros((n_users, n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set...\n",
      "Finished loading.\n",
      "Size of rating matrix 943*1682.\n",
      "Effective score number of the training set 80000.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>887431973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1       5  874965758\n",
       "1        1        2       3  876893171\n",
       "2        1        3       4  878542960\n",
       "3        1        4       3  876893119\n",
       "4        1        6       5  887431973"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(trainingset_file, sep='\\t', names=names)\n",
    "print('Load training set...')\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "print('Finished loading.')\n",
    "print('Size of rating matrix %d*%d.' % (n_users, n_items))\n",
    "print('Effective score number of the training set %d.' % len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix density of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix density of training set is: 5.04%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cal_sparsity():\n",
    "    sparsity = float(len(ratings.nonzero()[0]))\n",
    "    sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "    sparsity *= 100\n",
    "    print('Matrix density of training set is: {:4.2f}%'.format(sparsity))\n",
    "\n",
    "cal_sparsity()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baseline model \n",
    "\n",
    "$$\\hat{r}_{xi}= \\bar{r}_{user\\; x} + \\bar{r}_{item\\; i} - \\mu$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exist User/Item mean NaN? False True\n",
      "Exist User/Item mean NaN? False False\n",
      "Finsh，population mean is 3.5311\n"
     ]
    }
   ],
   "source": [
    "def rmse(pred, actual):\n",
    "    '''calculate prediction rmse'''\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return np.sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "def cal_mean():\n",
    "    '''Calculate mean value'''\n",
    "    # population mean, each uesr mean, each item mean \n",
    "    global all_mean, user_mean, item_mean \n",
    "    all_mean = np.mean(ratings[ratings!=0])\n",
    "    user_mean = sum(ratings.T) / sum((ratings!=0).T)\n",
    "    item_mean = sum(ratings) / sum((ratings!=0))\n",
    "    print('Exist User/Item mean NaN?', np.isnan(user_mean).any(), np.isnan(item_mean).any())\n",
    "    # fill in NaN with population mean\n",
    "    user_mean = np.where(np.isnan(user_mean), all_mean, user_mean)\n",
    "    item_mean = np.where(np.isnan(item_mean), all_mean, item_mean)\n",
    "    print('Exist User/Item mean NaN?', np.isnan(user_mean).any(), np.isnan(item_mean).any())\n",
    "    print('Finsh，population mean is %.4f' % all_mean)\n",
    "\n",
    "cal_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive(user, item):\n",
    "    prediction = item_mean[item] + user_mean[user] - all_mean\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test set...\n",
      "Test set size: 20000\n",
      "Navie model:\n",
      "Test set rmse: 0.9691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading test set...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('Test set size: %d' % len(test_df))\n",
    "print('Navie model:')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_naive(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('Test set rmse: %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item-item based cf model \n",
    "\n",
    "+ use Cosine distance to calculate similarilty:\n",
    "    $$sim(x, y) = \\frac{r_x\\cdot r_y}{\\|r_x\\|\\|r_y\\|}$$\n",
    "    \n",
    "+ weighted prediction:\n",
    "    $$\\hat{r}_{xi} = \\frac{\\sum_{j\\in N(x)}s_{ij}\\cdot r_{xj}}{\\sum_{j\\in N(x)} s_{ij}}\\;,$$\n",
    "    where $N(x)$ is the rating data by user $x$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_similarity(ratings, kind, epsilon=1e-9):\n",
    "    '''uisng Cosine distance to calculate similarilty'''\n",
    "    '''epsilon: aviod Divide-by-zero error ，Correct it.'''\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate similarity martrix...\n",
      "Finished.\n",
      "example: (item-item)\n",
      "[[1.    0.296 0.279 0.388 0.252 0.114 0.518 0.41  0.416 0.199]\n",
      " [0.296 1.    0.177 0.405 0.211 0.099 0.331 0.31  0.207 0.152]\n",
      " [0.279 0.177 1.    0.275 0.118 0.104 0.311 0.125 0.207 0.121]\n",
      " [0.388 0.405 0.275 1.    0.265 0.091 0.411 0.391 0.357 0.219]\n",
      " [0.252 0.211 0.118 0.265 1.    0.016 0.28  0.214 0.202 0.031]\n",
      " [0.114 0.099 0.104 0.091 0.016 1.    0.128 0.065 0.164 0.139]\n",
      " [0.518 0.331 0.311 0.411 0.28  0.128 1.    0.342 0.43  0.279]\n",
      " [0.41  0.31  0.125 0.391 0.214 0.065 0.342 1.    0.364 0.166]\n",
      " [0.416 0.207 0.207 0.357 0.202 0.164 0.43  0.364 1.    0.25 ]\n",
      " [0.199 0.152 0.121 0.219 0.031 0.139 0.279 0.166 0.25  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print('Calculate similarity martrix...')\n",
    "user_similarity = cal_similarity(ratings, kind='user')\n",
    "item_similarity = cal_similarity(ratings, kind='item')\n",
    "print('Finished.')\n",
    "print('example: (item-item)')\n",
    "print(np.round_(item_similarity[:10,:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_itemCF(user, item, k=100):\n",
    "    '''item-item CF, predict rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    prediction = ratings[user, nzero].dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test set...\n",
      "Test set size 20000\n",
      "item-item CF:\n",
      "Test set rmse: 1.0042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading test set...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('Test set size %d' % len(test_df))\n",
    "print('item-item CF:')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_itemCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('Test set rmse: %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-user based CF model \n",
    "+ Cold start problem: when denominator is $0$, the result would be $NaN$. Thus we use the baseline result to replace $NaN$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_userCF(user, item, k=100):\n",
    "    '''user-user CF, predict rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = ratings[nzero, item].dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero])\n",
    "    # Cold start problem: the item has not been scored yet\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test set...\n",
      "Test set size 20000\n",
      "user-user CF:\n",
      "Test set rmse: 1.0133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading test set...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('Test set size %d' % len(test_df))\n",
    "print('user-user CF:')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('Test set rmse: %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based CF combining baseline model \n",
    "+ prediction model:\n",
    "    $$\\hat{r}_{xi} = b_{xi} + \\frac{\\sum_{j\\in N(x)}s_{ij}\\cdot (r_{xj} - b_{xj})}{\\sum_{j\\in N(x)} s_{ij}}\\;,$$\n",
    "    where $b_{xi}$ is the predicted rate for user $x$ to item $i$ using baseline model, and $N(x)$ is the rating data by user $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test dataset...\n",
      "Test set size 20000\n",
      "user-based CF with baseline:\n",
      "Test set rmse: 0.9519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_userCF_baseline(user, item, k=100):\n",
    "    '''user-user CF combining baseline, predict rating'''\n",
    "    nzero = ratings[:,item].nonzero()[0]\n",
    "    baseline = user_mean + item_mean[item] - all_mean\n",
    "    prediction = (ratings[nzero, item] - baseline[nzero]).dot(user_similarity[user, nzero])\\\n",
    "                / sum(user_similarity[user, nzero]) + baseline[user]\n",
    "    if np.isnan(prediction):\n",
    "        prediction = baseline[user]\n",
    "    return prediction\n",
    "\n",
    "print('loading test dataset...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('Test set size %d' % len(test_df))\n",
    "print('user-based CF with baseline:')\n",
    "\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_userCF_baseline(user, item))\n",
    "    targets.append(actual)\n",
    "    \n",
    "print('Test set rmse: %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified model\n",
    "+ further improve item-based CF with baseline model by regulating rating in range (1, 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test dataset...\n",
      "Test set size 20000\n",
      "item-based CF with baseline:\n",
      "Test set rmse: 0.9344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_biasCF(user, item, k=100):\n",
    "    '''item based CF combining baseline, predict rating'''\n",
    "    nzero = ratings[user].nonzero()[0]\n",
    "    baseline = item_mean + user_mean[user] - all_mean\n",
    "    prediction = (ratings[user, nzero] - baseline[nzero]).dot(item_similarity[item, nzero])\\\n",
    "                / sum(item_similarity[item, nzero]) + baseline[item]\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "    if prediction < 1:\n",
    "        prediciton = 1\n",
    "    return prediction\n",
    "\n",
    "print('loading test dataset...')\n",
    "test_df = pd.read_csv(testset_file, sep='\\t', names=names)\n",
    "test_df.head()\n",
    "predictions = []\n",
    "targets = []\n",
    "print('Test set size %d' % len(test_df))\n",
    "print('item-based CF with baseline:')\n",
    "for row in test_df.itertuples():\n",
    "    user, item, actual = row[1]-1, row[2]-1, row[3]\n",
    "    predictions.append(predict_biasCF(user, item))\n",
    "    targets.append(actual)\n",
    "\n",
    "print('Test set rmse: %.4f' % rmse(np.array(predictions), np.array(targets)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
