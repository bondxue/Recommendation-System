{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sortedcontainers import SortedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "+ Note: user ids are ordered sequentially from 1..138493 with no missing numbers, movie ids are integers from 1..131262 and NOT all movie ids appear, there are only 26744 movie ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movielens-20m-dataset/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the user ids go from 0...N-1\n",
    "df.userId = df.userId - 1\n",
    "\n",
    "# create a mapping for movie ids\n",
    "unique_movie_ids = set(df.movieId.values)\n",
    "movie2idx = {}\n",
    "count = 0\n",
    "for movie_id in unique_movie_ids:\n",
    "  movie2idx[movie_id] = count\n",
    "  count += 1\n",
    "\n",
    "# add them to the data frame\n",
    "# takes awhile\n",
    "df['movie_idx'] = df.apply(lambda row: movie2idx[row.movieId], axis=1)\n",
    "\n",
    "df = df.drop(columns=['timestamp']) # we don't need timestamp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movielens-20m-dataset/edited_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shrinking data \n",
    "+ full dataset is too large to perform O(n^2) algorithm \n",
    "+ select subset of users and moives, users who rated the most movies, movies who've been rated by the most users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe size: 20000263\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('movielens-20m-dataset/edited_rating.csv')\n",
    "print(\"original dataframe size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>4.5</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating  movie_idx\n",
       "960      10        1     4.5          1\n",
       "961      10       10     2.5         10\n",
       "962      10       19     3.5         19\n",
       "963      10       32     5.0         32\n",
       "964      10       39     4.5         39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = df.userId.max() + 1 # number of users\n",
    "M = df.movie_idx.max() + 1 # number of movies\n",
    "\n",
    "user_ids_count = Counter(df.userId)\n",
    "movie_ids_count = Counter(df.movie_idx)\n",
    "\n",
    "# number of users and movies we would like to keep\n",
    "n = 10000\n",
    "m = 2000\n",
    "\n",
    "user_ids = [u for u, c in user_ids_count.most_common(n)]\n",
    "movie_ids = [m for m, c in movie_ids_count.most_common(m)]\n",
    "\n",
    "# make a copy, otherwise ids won't be overwritten\n",
    "df_small = df[df.userId.isin(user_ids) & df.movie_idx.isin(movie_ids)].copy()\n",
    "\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 10000\n",
      "j: 2000\n"
     ]
    }
   ],
   "source": [
    "# need to remake user ids and movie ids since they are no longer sequential\n",
    "new_user_id_map = {}\n",
    "i = 0\n",
    "for old in user_ids:\n",
    "  new_user_id_map[old] = i\n",
    "  i += 1\n",
    "print(\"i:\", i)\n",
    "\n",
    "new_movie_id_map = {}\n",
    "j = 0\n",
    "for old in movie_ids:\n",
    "  new_movie_id_map[old] = j\n",
    "  j += 1\n",
    "print(\"j:\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting new ids\n",
      "max user id: 9999\n",
      "max movie id: 1999\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting new ids\")\n",
    "df_small.loc[:, 'userId'] = df_small.apply(lambda row: new_user_id_map[row.userId], axis=1)\n",
    "df_small.loc[:, 'movie_idx'] = df_small.apply(lambda row: new_movie_id_map[row.movie_idx], axis=1)\n",
    "# df_small.drop(columns=['userId', 'movie_idx'])\n",
    "# df_small.rename(index=str, columns={'new_userId': 'userId', 'new_movie_idx': 'movie_idx'})\n",
    "print(\"max user id:\", df_small.userId.max())\n",
    "print(\"max movie id:\", df_small.movie_idx.max())\n",
    "print(\"small dataframe size:\", len(df_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.to_csv('movielens-20m-dataset/small_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table to Dictionary\n",
    "+ user2movie: user ID -> movie ID\n",
    "+ movie2user: movie ID -> user ID\n",
    "+ usermovie2rating: (user ID, movie ID) -> rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movielens-20m-dataset/small_rating.csv')\n",
    "\n",
    "N = df.userId.max() + 1 # number of users\n",
    "M = df.movie_idx.max() + 1 # number of movies\n",
    "\n",
    "# split into train and test\n",
    "df = shuffle(df)\n",
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff]\n",
    "df_test = df.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: update_user2movie_and_movie2user\n",
      "processed: 0.023\n",
      "processed: 0.046\n",
      "processed: 0.070\n",
      "processed: 0.093\n",
      "processed: 0.116\n",
      "processed: 0.139\n",
      "processed: 0.162\n",
      "processed: 0.185\n",
      "processed: 0.209\n",
      "processed: 0.232\n",
      "processed: 0.255\n",
      "processed: 0.278\n",
      "processed: 0.301\n",
      "processed: 0.325\n",
      "processed: 0.348\n",
      "processed: 0.371\n",
      "processed: 0.394\n",
      "processed: 0.417\n",
      "processed: 0.440\n",
      "processed: 0.464\n",
      "processed: 0.487\n",
      "processed: 0.510\n",
      "processed: 0.533\n",
      "processed: 0.556\n",
      "processed: 0.580\n",
      "processed: 0.603\n",
      "processed: 0.626\n",
      "processed: 0.649\n",
      "processed: 0.672\n",
      "processed: 0.695\n",
      "processed: 0.719\n",
      "processed: 0.742\n",
      "processed: 0.765\n",
      "processed: 0.788\n",
      "processed: 0.811\n",
      "processed: 0.835\n",
      "processed: 0.858\n",
      "processed: 0.881\n",
      "processed: 0.904\n",
      "processed: 0.927\n",
      "processed: 0.950\n",
      "processed: 0.974\n",
      "processed: 0.997\n",
      "Calling: update_usermovie2rating_test\n",
      "processed: 0.093\n",
      "processed: 0.185\n",
      "processed: 0.278\n",
      "processed: 0.371\n",
      "processed: 0.464\n",
      "processed: 0.556\n",
      "processed: 0.649\n",
      "processed: 0.742\n",
      "processed: 0.835\n",
      "processed: 0.927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1761954    None\n",
       "22147      None\n",
       "4476511    None\n",
       "3719981    None\n",
       "4884866    None\n",
       "1886693    None\n",
       "2010095    None\n",
       "1534684    None\n",
       "1872587    None\n",
       "2697224    None\n",
       "3779918    None\n",
       "3087537    None\n",
       "1599772    None\n",
       "4618985    None\n",
       "2142242    None\n",
       "354729     None\n",
       "2168094    None\n",
       "1705211    None\n",
       "2509466    None\n",
       "4355676    None\n",
       "922175     None\n",
       "278472     None\n",
       "1423300    None\n",
       "4844620    None\n",
       "1423051    None\n",
       "547157     None\n",
       "1356751    None\n",
       "1910798    None\n",
       "3337704    None\n",
       "4373420    None\n",
       "           ... \n",
       "2830127    None\n",
       "1650971    None\n",
       "1457496    None\n",
       "4713814    None\n",
       "1431263    None\n",
       "5333704    None\n",
       "3135237    None\n",
       "3009113    None\n",
       "4120737    None\n",
       "1667744    None\n",
       "2422003    None\n",
       "2283902    None\n",
       "4211       None\n",
       "3474391    None\n",
       "4380524    None\n",
       "2453923    None\n",
       "1884382    None\n",
       "2432942    None\n",
       "279290     None\n",
       "812743     None\n",
       "1463157    None\n",
       "4592163    None\n",
       "900890     None\n",
       "4187977    None\n",
       "246352     None\n",
       "1882367    None\n",
       "3127037    None\n",
       "3347540    None\n",
       "1701404    None\n",
       "63381      None\n",
       "Length: 1078405, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a dictionary to tell us which users have rated which movies\n",
    "user2movie = {}\n",
    "# a dicationary to tell us which movies have been rated by which users\n",
    "movie2user = {}\n",
    "# a dictionary to look up ratings\n",
    "usermovie2rating = {}\n",
    "print(\"Calling: update_user2movie_and_movie2user\")\n",
    "count = 0\n",
    "def update_user2movie_and_movie2user(row):\n",
    "  global count\n",
    "  count += 1\n",
    "  if count % 100000 == 0:\n",
    "    print(\"processed: %.3f\" % (float(count)/cutoff))\n",
    "\n",
    "  i = int(row.userId)\n",
    "  j = int(row.movie_idx)\n",
    "  if i not in user2movie:\n",
    "    user2movie[i] = [j]\n",
    "  else:\n",
    "    user2movie[i].append(j)\n",
    "\n",
    "  if j not in movie2user:\n",
    "    movie2user[j] = [i]\n",
    "  else:\n",
    "    movie2user[j].append(i)\n",
    "\n",
    "  usermovie2rating[(i,j)] = row.rating\n",
    "df_train.apply(update_user2movie_and_movie2user, axis=1)\n",
    "\n",
    "# test ratings dictionary\n",
    "usermovie2rating_test = {}\n",
    "print(\"Calling: update_usermovie2rating_test\")\n",
    "count = 0\n",
    "def update_usermovie2rating_test(row):\n",
    "  global count\n",
    "  count += 1\n",
    "  if count % 100000 == 0:\n",
    "    print(\"processed: %.3f\" % (float(count)/len(df_test)))\n",
    "\n",
    "  i = int(row.userId)\n",
    "  j = int(row.movie_idx)\n",
    "  usermovie2rating_test[(i,j)] = row.rating\n",
    "df_test.apply(update_usermovie2rating_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: these are not really JSONs\n",
    "with open('user2movie.json', 'wb') as f:\n",
    "  pickle.dump(user2movie, f)\n",
    "\n",
    "with open('movie2user.json', 'wb') as f:\n",
    "  pickle.dump(movie2user, f)\n",
    "\n",
    "with open('usermovie2rating.json', 'wb') as f:\n",
    "  pickle.dump(usermovie2rating, f)\n",
    "\n",
    "with open('usermovie2rating_test.json', 'wb') as f:\n",
    "  pickle.dump(usermovie2rating_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user2movie.json', 'rb') as f:\n",
    "  user2movie = pickle.load(f)\n",
    "\n",
    "with open('movie2user.json', 'rb') as f:\n",
    "  movie2user = pickle.load(f)\n",
    "\n",
    "with open('usermovie2rating.json', 'rb') as f:\n",
    "  usermovie2rating = pickle.load(f)\n",
    "\n",
    "with open('usermovie2rating_test.json', 'rb') as f:\n",
    "  usermovie2rating_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 10000 M: 2000\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "N = np.max(list(user2movie.keys())) + 1\n",
    "# the test set may contain movies the train set doesn't have data on\n",
    "m1 = np.max(list(movie2user.keys()))\n",
    "m2 = np.max([m for (u, m), r in usermovie2rating_test.items()])\n",
    "M = max(m1, m2) + 1\n",
    "print(\"N:\", N, \"M:\", M)\n",
    "\n",
    "if N > 10000:\n",
    "  print(\"N =\", N, \"are you sure you want to continue?\")\n",
    "  print(\"Comment out these lines if so...\")\n",
    "  exit()\n",
    "\n",
    "\n",
    "# to find the user similarities, you have to do O(N^2 * M) calculations!\n",
    "# in the \"real-world\" you'd want to parallelize this\n",
    "# note: we really only have to do half the calculations, since w_ij is symmetric\n",
    "K = 25 # number of neighbors we'd like to consider\n",
    "limit = 5 # number of common movies users must have in common in order to consider\n",
    "neighbors = [] # store neighbors in this list\n",
    "averages = [] # each user's average rating for later use\n",
    "deviations = [] # each user's deviation for later use\n",
    "for i in range(N):\n",
    "  # find the 25 closest users to user i\n",
    "  movies_i = user2movie[i]\n",
    "  movies_i_set = set(movies_i)\n",
    "\n",
    "  # calculate avg and deviation\n",
    "  ratings_i = { movie:usermovie2rating[(i, movie)] for movie in movies_i }\n",
    "  avg_i = np.mean(list(ratings_i.values()))\n",
    "  dev_i = { movie:(rating - avg_i) for movie, rating in ratings_i.items() }\n",
    "  dev_i_values = np.array(list(dev_i.values()))\n",
    "  sigma_i = np.sqrt(dev_i_values.dot(dev_i_values))\n",
    "\n",
    "  # save these for later use\n",
    "  averages.append(avg_i)\n",
    "  deviations.append(dev_i)\n",
    "\n",
    "  sl = SortedList()\n",
    "  for j in range(N):\n",
    "    # don't include yourself\n",
    "    if j != i:\n",
    "      movies_j = user2movie[j]\n",
    "      movies_j_set = set(movies_j)\n",
    "      common_movies = (movies_i_set & movies_j_set) # intersection\n",
    "      if len(common_movies) > limit:\n",
    "        # calculate avg and deviation\n",
    "        ratings_j = { movie:usermovie2rating[(j, movie)] for movie in movies_j }\n",
    "        avg_j = np.mean(list(ratings_j.values()))\n",
    "        dev_j = { movie:(rating - avg_j) for movie, rating in ratings_j.items() }\n",
    "        dev_j_values = np.array(list(dev_j.values()))\n",
    "        sigma_j = np.sqrt(dev_j_values.dot(dev_j_values))\n",
    "\n",
    "        # calculate correlation coefficient\n",
    "        numerator = sum(dev_i[m]*dev_j[m] for m in common_movies)\n",
    "        w_ij = numerator / (sigma_i * sigma_j)\n",
    "\n",
    "        # insert into sorted list and truncate\n",
    "        # negate weight, because list is sorted ascending\n",
    "        # maximum value (1) is \"closest\"\n",
    "        sl.add((-w_ij, j))\n",
    "        if len(sl) > K:\n",
    "          del sl[-1]\n",
    "\n",
    "  # store the neighbors\n",
    "  neighbors.append(sl)\n",
    "\n",
    "  # print out useful things\n",
    "  if i % 1 == 0:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "# using neighbors, calculate train and test MSE\n",
    "\n",
    "def predict(i, m):\n",
    "  # calculate the weighted sum of deviations\n",
    "  numerator = 0\n",
    "  denominator = 0\n",
    "  for neg_w, j in neighbors[i]:\n",
    "    # remember, the weight is stored as its negative\n",
    "    # so the negative of the negative weight is the positive weight\n",
    "    try:\n",
    "      numerator += -neg_w * deviations[j][m]\n",
    "      denominator += abs(neg_w)\n",
    "    except KeyError:\n",
    "      # neighbor may not have rated the same movie\n",
    "      # don't want to do dictionary lookup twice\n",
    "      # so just throw exception\n",
    "      pass\n",
    "\n",
    "  if denominator == 0:\n",
    "    prediction = averages[i]\n",
    "  else:\n",
    "    prediction = numerator / denominator + averages[i]\n",
    "  prediction = min(5, prediction)\n",
    "  prediction = max(0.5, prediction) # min rating is 0.5\n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = []\n",
    "train_targets = []\n",
    "for (i, m), target in usermovie2rating.items():\n",
    "  # calculate the prediction for this movie\n",
    "  prediction = predict(i, m)\n",
    "\n",
    "  # save the prediction and target\n",
    "  train_predictions.append(prediction)\n",
    "  train_targets.append(target)\n",
    "\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "# same thing for test set\n",
    "for (i, m), target in usermovie2rating_test.items():\n",
    "  # calculate the prediction for this movie\n",
    "  prediction = predict(i, m)\n",
    "\n",
    "  # save the prediction and target\n",
    "  test_predictions.append(prediction)\n",
    "  test_targets.append(target)\n",
    "\n",
    "\n",
    "# calculate accuracy\n",
    "def mse(p, t):\n",
    "  p = np.array(p)\n",
    "  t = np.array(t)\n",
    "  return np.mean((p - t)**2)\n",
    "\n",
    "print('train mse:', mse(train_predictions, train_targets))\n",
    "print('test mse:', mse(test_predictions, test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
